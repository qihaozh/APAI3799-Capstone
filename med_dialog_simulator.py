"""
MedDialogSimulator - åŸºäºä¸­å›½åŒ»ç–—å¯¹è¯æ•°æ®é›†çš„æ‚£è€…-åŒ»ç”Ÿå¯¹è¯æ¨¡æ‹Ÿå™¨

è¯¥æ¨¡å—ä» Medical-Dialogue-Dataset-Chinese æ•°æ®é›†ä¸­è§£æçœŸå®çš„åŒ»ç–—å¯¹è¯ï¼Œ
å¹¶åˆ©ç”¨å¤šç§ AI æ¨¡å‹ï¼ˆGoogle Gemini / OpenAI ChatGPT / Anthropic Claudeï¼‰
æ¥æ¨¡æ‹Ÿæ‚£è€…ä¸åŒ»ç”Ÿä¹‹é—´çš„å¤šè½®å¯¹è¯ã€‚

æ”¯æŒçš„æ¨¡å‹åç«¯:
  - gemini   : Google Gemini (é»˜è®¤ gemini-2.0-flash)   â€” pip install google-genai
  - chatgpt  : OpenAI GPT ç³»åˆ— (é»˜è®¤ gpt-4o-mini)      â€” pip install openai
  - claude   : Anthropic Claude (é»˜è®¤ claude-sonnet-4-20250514) â€” pip install anthropic
"""

from __future__ import annotations

import json
import os
import random
import re
import textwrap
from dataclasses import dataclass, field, asdict
from pathlib import Path
from typing import Generator, Literal

# ---------------------------------------------------------------------------
# Data structures
# ---------------------------------------------------------------------------

@dataclass
class DialogueTurn:
    """å¯¹è¯ä¸­çš„å•è½®æ¶ˆæ¯ã€‚"""
    role: Literal["patient", "doctor"]  # è§’è‰²ï¼šç—…äºº / åŒ»ç”Ÿ
    text: str                            # æ¶ˆæ¯å†…å®¹

@dataclass
class MedicalRecord:
    """ä»æ•°æ®é›†ä¸­è§£æå‡ºçš„ä¸€æ¡å®Œæ•´åŒ»ç–—è®°å½•ã€‚"""
    record_id: int = -1
    url: str = ""
    hospital: str = ""
    department: str = ""
    disease: str = ""
    description: str = ""
    hope: str = ""
    allergy: str = ""
    medical_history: str = ""
    dialogue: list[DialogueTurn] = field(default_factory=list)
    diagnosis: str = ""
    suggestion: str = ""

    # ---- è¾…åŠ©æ–¹æ³• ----
    def to_dict(self) -> dict:
        return asdict(self)

    def patient_profile_prompt(self) -> str:
        """å°†ç—…äººä¿¡æ¯ç»„ç»‡æˆå¯ä¾› LLM æ‰®æ¼”ç—…äººçš„ prompt ç‰‡æ®µã€‚"""
        parts = [
            f"ç–¾ç—…/ä¸»è¯‰: {self.disease}",
            f"ç—…æƒ…æè¿°: {self.description}",
        ]
        if self.allergy:
            parts.append(f"è¿‡æ•å²: {self.allergy}")
        if self.medical_history:
            parts.append(f"æ—¢å¾€ç—…å²: {self.medical_history}")
        if self.hope:
            parts.append(f"å¸Œæœ›è·å¾—çš„å¸®åŠ©: {self.hope}")
        return "\n".join(parts)

    def doctor_profile_prompt(self) -> str:
        """å°†åŒ»ç”Ÿä¿¡æ¯ç»„ç»‡æˆå¯ä¾› LLM æ‰®æ¼”åŒ»ç”Ÿçš„ prompt ç‰‡æ®µã€‚"""
        parts = [
            f"åŒ»é™¢: {self.hospital}",
            f"ç§‘å®¤: {self.department}",
        ]
        if self.diagnosis:
            parts.append(f"å‚è€ƒè¯Šæ–­: {self.diagnosis}")
        if self.suggestion:
            parts.append(f"å‚è€ƒå»ºè®®: {self.suggestion}")
        return "\n".join(parts)

    def reference_dialogue_text(self) -> str:
        """å°†çœŸå®å¯¹è¯æ ¼å¼åŒ–ä¸ºå¯è¯»æ–‡æœ¬ã€‚"""
        if not self.dialogue:
            return "ï¼ˆè¯¥è®°å½•æ²¡æœ‰å¯¹è¯å†…å®¹ï¼‰"
        lines: list[str] = []
        for turn in self.dialogue:
            role_label = "ç—…äºº" if turn.role == "patient" else "åŒ»ç”Ÿ"
            lines.append(f"{role_label}ï¼š{turn.text}")
        return "\n".join(lines)


# ---------------------------------------------------------------------------
# Dataset parser
# ---------------------------------------------------------------------------

class DatasetParser:
    """è§£æ Medical-Dialogue-Dataset-Chinese æ•°æ®é›†çš„ .txt æ–‡ä»¶ã€‚"""

    def __init__(self, dataset_dir: str | Path):
        self.dataset_dir = Path(dataset_dir)
        if not self.dataset_dir.is_dir():
            raise FileNotFoundError(f"æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: {self.dataset_dir}")

    def available_files(self) -> list[Path]:
        """åˆ—å‡ºæ•°æ®é›†ç›®å½•ä¸‹çš„æ‰€æœ‰ .txt æ–‡ä»¶ã€‚"""
        return sorted(self.dataset_dir.glob("*.txt"))

    # ------------------------------------------------------------------ #
    # ä¸»è§£ææ–¹æ³•
    # ------------------------------------------------------------------ #
    def parse_file(self, filepath: str | Path, *, limit: int | None = None) -> list[MedicalRecord]:
        """
        è§£æå•ä¸ªæ•°æ®æ–‡ä»¶ï¼Œè¿”å› MedicalRecord åˆ—è¡¨ã€‚

        Parameters
        ----------
        filepath : str | Path
            æ•°æ®æ–‡ä»¶è·¯å¾„ã€‚
        limit : int | None
            æœ€å¤šè§£æå¤šå°‘æ¡è®°å½•ï¼ŒNone è¡¨ç¤ºå…¨éƒ¨ã€‚
        """
        filepath = Path(filepath)
        records: list[MedicalRecord] = []
        current_lines: list[str] = []

        with open(filepath, "r", encoding="utf-8") as fh:
            for line in fh:
                stripped = line.rstrip("\n")
                # æ£€æµ‹åˆ°æ–°è®°å½•çš„èµ·å§‹è¡Œ
                if re.match(r"^id=\d+", stripped) and current_lines:
                    rec = self._parse_block(current_lines)
                    if rec is not None:
                        records.append(rec)
                        if limit is not None and len(records) >= limit:
                            return records
                    current_lines = []
                current_lines.append(stripped)

            # æœ€åä¸€æ¡è®°å½•
            if current_lines:
                rec = self._parse_block(current_lines)
                if rec is not None:
                    records.append(rec)

        return records

    def iter_records(self, filepath: str | Path) -> Generator[MedicalRecord, None, None]:
        """é€æ¡ yield è®°å½•ï¼Œé€‚åˆå¤„ç†å¤§æ–‡ä»¶ã€‚"""
        filepath = Path(filepath)
        current_lines: list[str] = []

        with open(filepath, "r", encoding="utf-8") as fh:
            for line in fh:
                stripped = line.rstrip("\n")
                if re.match(r"^id=\d+", stripped) and current_lines:
                    rec = self._parse_block(current_lines)
                    if rec is not None:
                        yield rec
                    current_lines = []
                current_lines.append(stripped)

            if current_lines:
                rec = self._parse_block(current_lines)
                if rec is not None:
                    yield rec

    def sample_records(
        self,
        filepath: str | Path,
        n: int = 5,
        *,
        with_dialogue: bool = True,
        seed: int | None = None,
    ) -> list[MedicalRecord]:
        """
        ä»æ–‡ä»¶ä¸­éšæœºé‡‡æ · n æ¡è®°å½•ã€‚

        Parameters
        ----------
        with_dialogue : bool
            è‹¥ä¸º Trueï¼Œåªé‡‡æ ·åŒ…å«å¯¹è¯çš„è®°å½•ã€‚
        """
        if seed is not None:
            random.seed(seed)

        # å…ˆé€šè¿‡ reservoir sampling æ”¶é›†å€™é€‰è®°å½•
        candidates: list[MedicalRecord] = []
        for rec in self.iter_records(filepath):
            if with_dialogue and not rec.dialogue:
                continue
            candidates.append(rec)

        if len(candidates) <= n:
            return candidates
        return random.sample(candidates, n)

    # ------------------------------------------------------------------ #
    # å†…éƒ¨è§£æ
    # ------------------------------------------------------------------ #
    def _parse_block(self, lines: list[str]) -> MedicalRecord | None:
        """è§£æä¸€æ¡è®°å½•çš„æ–‡æœ¬å—ã€‚"""
        text = "\n".join(lines)
        rec = MedicalRecord()

        # --- id ---
        m = re.search(r"^id=(\d+)", text)
        if m:
            rec.record_id = int(m.group(1))
        else:
            return None

        # --- url ---
        m = re.search(r"(https?://\S+)", text)
        if m:
            rec.url = m.group(1)

        # --- Doctor faculty ---
        m = re.search(r"Doctor faculty\n(.+?)(?:\n\n|\nDescription)", text, re.DOTALL)
        if m:
            faculty_text = m.group(1).strip()
            parts = [p.strip() for p in faculty_text.split("  ") if p.strip()]
            if len(parts) >= 2:
                rec.hospital = parts[0]
                rec.department = parts[1]
            elif parts:
                rec.hospital = parts[0]

        # --- Description ---
        desc_match = re.search(r"Description\n(.*?)(?=\nDialogue\n|\nDiagnosis and suggestions\n|\nid=|\Z)", text, re.DOTALL)
        if desc_match:
            desc_text = desc_match.group(1)
            # ç–¾ç—…
            m = re.search(r"ç–¾ç—…[ï¼š:]\s*\n?(.+?)(?=\nç—…æƒ…æè¿°|$)", desc_text, re.DOTALL)
            if m:
                rec.disease = m.group(1).strip()
            # ç—…æƒ…æè¿°
            m = re.search(r"ç—…æƒ…æè¿°[ï¼š:]\s*\n?(.+?)(?=\nå¸Œæœ›è·å¾—|$)", desc_text, re.DOTALL)
            if m:
                rec.description = m.group(1).strip()
            # å¸Œæœ›è·å¾—çš„å¸®åŠ©
            m = re.search(r"å¸Œæœ›è·å¾—çš„å¸®åŠ©[ï¼š:]\s*\n?(.+?)(?=\næ€€å­•æƒ…å†µ|æ‚£ç—…å¤šä¹…|\nç”¨è¯æƒ…å†µ|\nè¿‡æ•å²|\næ—¢å¾€ç—…å²|$)", desc_text, re.DOTALL)
            if m:
                rec.hope = m.group(1).strip()
            # è¿‡æ•å²
            m = re.search(r"è¿‡æ•å²[ï¼š:]\s*\n?(.+?)(?=\næ—¢å¾€ç—…å²|$)", desc_text, re.DOTALL)
            if m:
                rec.allergy = m.group(1).strip()
            # æ—¢å¾€ç—…å²
            m = re.search(r"æ—¢å¾€ç—…å²[ï¼š:]\s*\n?(.+?)(?=\n|$)", desc_text, re.DOTALL)
            if m:
                rec.medical_history = m.group(1).strip()

        # --- Dialogue ---
        dial_match = re.search(r"Dialogue\n(.*?)(?=\nDiagnosis and suggestions\n|\nid=|\Z)", text, re.DOTALL)
        if dial_match:
            dial_text = dial_match.group(1).strip()
            rec.dialogue = self._parse_dialogue(dial_text)

        # --- Diagnosis and suggestions ---
        diag_match = re.search(r"Diagnosis and suggestions\n(.*?)(?=\nid=|\Z)", text, re.DOTALL)
        if diag_match:
            diag_text = diag_match.group(1)
            m = re.search(r"ç—…æƒ…æ‘˜è¦åŠåˆæ­¥å°è±¡[ï¼š:]\s*\n?(.+?)(?=\næ€»ç»“å»ºè®®|$)", diag_text, re.DOTALL)
            if m:
                rec.diagnosis = m.group(1).strip()
            m = re.search(r"æ€»ç»“å»ºè®®[ï¼š:]\s*\n?(.+?)(?=$)", diag_text, re.DOTALL)
            if m:
                rec.suggestion = m.group(1).strip()

        return rec

    @staticmethod
    def _parse_dialogue(text: str) -> list[DialogueTurn]:
        """
        è§£æå¯¹è¯æ–‡æœ¬ï¼Œå¤„ç† `ç—…äººï¼š` å’Œ `åŒ»ç”Ÿï¼š` äº¤æ›¿å‡ºç°çš„æƒ…å†µã€‚
        æ•°æ®é›†ä¸­ä¸€è¡Œå¯èƒ½åŒæ—¶åŒ…å«å¤šä¸ªè§’è‰²çš„å‘è¨€ï¼ˆç©ºæ ¼æ‹¼æ¥ï¼‰ï¼Œéœ€è¦æ‹†åˆ†ã€‚
        """
        turns: list[DialogueTurn] = []
        # ä½¿ç”¨æ­£åˆ™æŒ‰è§’è‰²æ ‡ç­¾åˆ‡åˆ†
        segments = re.split(r"(ç—…äºº[ï¼š:]|åŒ»ç”Ÿ[ï¼š:])", text)
        # segments å½¢å¦‚ ['', 'ç—…äººï¼š', 'å†…å®¹...', 'åŒ»ç”Ÿï¼š', 'å†…å®¹...', ...]
        i = 1  # è·³è¿‡ç¬¬ä¸€ä¸ªç©ºå­—ç¬¦ä¸²
        while i < len(segments) - 1:
            tag = segments[i].strip().rstrip("ï¼š:")
            content = segments[i + 1].strip()
            content = re.sub(r"\s{2,}", " ", content)  # å‹ç¼©å¤šä½™ç©ºç™½
            if content:
                role: Literal["patient", "doctor"] = "patient" if tag == "ç—…äºº" else "doctor"
                turns.append(DialogueTurn(role=role, text=content))
            i += 2
        return turns


# ---------------------------------------------------------------------------
# AI Model Backends (Strategy Pattern)
# ---------------------------------------------------------------------------

class BaseModelBackend:
    """AI æ¨¡å‹åç«¯çš„åŸºç±»ã€‚"""

    def generate(self, messages: list[dict], *, temperature: float = 0.7) -> str:
        raise NotImplementedError

    @property
    def name(self) -> str:
        return self.__class__.__name__


class GeminiBackend(BaseModelBackend):
    """
    Google Gemini æ¨¡å‹åç«¯ã€‚

    éœ€è¦å®‰è£…: pip install google-genai
    éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡ GOOGLE_API_KEY æˆ–åœ¨æ„é€ æ—¶ä¼ å…¥ api_keyã€‚
    """

    def __init__(self, api_key: str | None = None, model: str = "gemini-2.0-flash"):
        try:
            from google import genai
            from google.genai import types
        except ImportError:
            raise ImportError(
                "è¯·å…ˆå®‰è£… google-genai: pip install google-genai"
            )

        self._api_key = api_key or os.environ.get("GOOGLE_API_KEY", "")
        if not self._api_key:
            raise ValueError(
                "è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GOOGLE_API_KEY æˆ–åœ¨æ„é€ æ—¶ä¼ å…¥ api_key"
            )
        self._model = model
        self._client = genai.Client(api_key=self._api_key)
        self._types = types

    @property
    def name(self) -> str:
        return f"Gemini ({self._model})"

    def generate(self, messages: list[dict], *, temperature: float = 0.7) -> str:
        """
        è°ƒç”¨ Gemini API ç”Ÿæˆå›å¤ã€‚

        Parameters
        ----------
        messages : list[dict]
            æ¶ˆæ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å« 'role' ('user'/'model') å’Œ 'text' å­—æ®µã€‚
        temperature : float
            ç”Ÿæˆæ¸©åº¦ï¼Œè¶Šé«˜è¶Šéšæœºã€‚
        """
        contents = []
        for msg in messages:
            role = msg["role"]  # 'user' or 'model'
            contents.append(
                self._types.Content(
                    role=role,
                    parts=[self._types.Part.from_text(text=msg["text"])],
                )
            )

        response = self._client.models.generate_content(
            model=self._model,
            contents=contents,
            config=self._types.GenerateContentConfig(
                temperature=temperature,
                max_output_tokens=2048,
            ),
        )
        return response.text.strip()


class OpenAICompatibleBackend(BaseModelBackend):
    """
    å…¼å®¹ OpenAI API æ ¼å¼çš„åç«¯ï¼ˆOpenAI / Azure OpenAI / æœ¬åœ° LLM ç­‰ï¼‰ã€‚

    éœ€è¦å®‰è£…: pip install openai
    """

    def __init__(
        self,
        api_key: str | None = None,
        model: str = "gpt-4o-mini",
        base_url: str | None = None,
    ):
        try:
            from openai import OpenAI
        except ImportError:
            raise ImportError("è¯·å…ˆå®‰è£… openai: pip install openai")

        self._api_key = api_key or os.environ.get("OPENAI_API_KEY", "")
        self._model = model
        self._client = OpenAI(api_key=self._api_key, base_url=base_url)

    @property
    def name(self) -> str:
        return f"OpenAI-compatible ({self._model})"

    def generate(self, messages: list[dict], *, temperature: float = 0.7) -> str:
        # è½¬æ¢ä¸º OpenAI æ¶ˆæ¯æ ¼å¼
        oai_messages = []
        for msg in messages:
            role = "assistant" if msg["role"] == "model" else msg["role"]
            oai_messages.append({"role": role, "content": msg["text"]})

        resp = self._client.chat.completions.create(
            model=self._model,
            messages=oai_messages,
            temperature=temperature,
            max_tokens=2048,
        )
        return resp.choices[0].message.content.strip()


class ClaudeBackend(BaseModelBackend):
    """
    Anthropic Claude æ¨¡å‹åç«¯ã€‚

    éœ€è¦å®‰è£…: pip install anthropic
    éœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡ ANTHROPIC_API_KEY æˆ–åœ¨æ„é€ æ—¶ä¼ å…¥ api_keyã€‚
    """

    def __init__(
        self,
        api_key: str | None = None,
        model: str = "claude-sonnet-4-20250514",
    ):
        try:
            import anthropic
        except ImportError:
            raise ImportError("è¯·å…ˆå®‰è£… anthropic: pip install anthropic")

        self._api_key = api_key or os.environ.get("ANTHROPIC_API_KEY", "")
        if not self._api_key:
            raise ValueError(
                "è¯·è®¾ç½®ç¯å¢ƒå˜é‡ ANTHROPIC_API_KEY æˆ–åœ¨æ„é€ æ—¶ä¼ å…¥ api_key"
            )
        self._model = model
        self._client = anthropic.Anthropic(api_key=self._api_key)

    @property
    def name(self) -> str:
        return f"Claude ({self._model})"

    def generate(self, messages: list[dict], *, temperature: float = 0.7) -> str:
        """
        è°ƒç”¨ Claude API ç”Ÿæˆå›å¤ã€‚

        Parameters
        ----------
        messages : list[dict]
            æ¶ˆæ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å« 'role' ('user'/'model') å’Œ 'text' å­—æ®µã€‚
        temperature : float
            ç”Ÿæˆæ¸©åº¦ã€‚
        """
        # ç¬¬ä¸€æ¡ user æ¶ˆæ¯å¯ä½œä¸º system prompt
        system_text = ""
        api_messages = []

        for i, msg in enumerate(messages):
            role = msg["role"]
            text = msg["text"]

            if i == 0 and role == "user":
                # å°†ç¬¬ä¸€æ¡ä½œä¸º system æŒ‡ä»¤
                system_text = text
                continue

            # Claude API ä½¿ç”¨ 'assistant' è€Œä¸æ˜¯ 'model'
            if role == "model":
                role = "assistant"
            api_messages.append({"role": role, "content": text})

        # ç¡®ä¿è‡³å°‘æœ‰ä¸€æ¡ user æ¶ˆæ¯
        if not api_messages:
            api_messages.append({"role": "user", "content": system_text})
            system_text = ""

        kwargs = dict(
            model=self._model,
            max_tokens=2048,
            temperature=temperature,
            messages=api_messages,
        )
        if system_text:
            kwargs["system"] = system_text

        response = self._client.messages.create(**kwargs)
        return response.content[0].text.strip()


# ---------------------------------------------------------------------------
# Backend factory
# ---------------------------------------------------------------------------

# æ”¯æŒçš„åç«¯åˆ«åæ˜ å°„
BACKEND_ALIASES: dict[str, list[str]] = {
    "gemini":  ["gemini", "google", "google-gemini"],
    "chatgpt": ["chatgpt", "openai", "gpt"],
    "claude":  ["claude", "anthropic"],
}


def create_backend(
    backend_type: str,
    *,
    api_key: str | None = None,
    model: str | None = None,
    base_url: str | None = None,
) -> BaseModelBackend:
    """
    å·¥å‚å‡½æ•° â€” æ ¹æ®åç§°åˆ›å»ºå¯¹åº”çš„ AI æ¨¡å‹åç«¯ã€‚

    Parameters
    ----------
    backend_type : str
        åç«¯ç±»å‹åç§°ã€‚æ”¯æŒä»¥ä¸‹å€¼ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰ï¼š
        - 'gemini' / 'google'       â†’ GeminiBackend
        - 'chatgpt' / 'openai' / 'gpt' â†’ OpenAICompatibleBackend
        - 'claude' / 'anthropic'    â†’ ClaudeBackend
    api_key : str | None
        API å¯†é’¥ï¼Œä¹Ÿå¯é€šè¿‡å¯¹åº”çš„ç¯å¢ƒå˜é‡è®¾ç½®ã€‚
    model : str | None
        æ¨¡å‹åç§°ï¼ŒNone åˆ™ä½¿ç”¨å„åç«¯çš„é»˜è®¤æ¨¡å‹ã€‚
    base_url : str | None
        ä»… OpenAI å…¼å®¹åç«¯ä½¿ç”¨ï¼Œç”¨äºè‡ªå®šä¹‰ API åœ°å€ã€‚

    Returns
    -------
    BaseModelBackend

    Examples
    --------
    >>> backend = create_backend("gemini", api_key="...")
    >>> backend = create_backend("chatgpt", model="gpt-4o")
    >>> backend = create_backend("claude", model="claude-sonnet-4-20250514")
    """
    key = backend_type.strip().lower()

    # è§£æåˆ«å
    resolved: str | None = None
    for canonical, aliases in BACKEND_ALIASES.items():
        if key in aliases:
            resolved = canonical
            break

    if resolved is None:
        supported = ", ".join(
            f"{k} ({'/'.join(v)})" for k, v in BACKEND_ALIASES.items()
        )
        raise ValueError(
            f"ä¸æ”¯æŒçš„åç«¯ç±»å‹: '{backend_type}'ã€‚æ”¯æŒçš„ç±»å‹: {supported}"
        )

    if resolved == "gemini":
        kwargs: dict = {"api_key": api_key}
        if model:
            kwargs["model"] = model
        return GeminiBackend(**kwargs)

    elif resolved == "chatgpt":
        kwargs = {"api_key": api_key}
        if model:
            kwargs["model"] = model
        if base_url:
            kwargs["base_url"] = base_url
        return OpenAICompatibleBackend(**kwargs)

    else:  # claude
        kwargs = {"api_key": api_key}
        if model:
            kwargs["model"] = model
        return ClaudeBackend(**kwargs)


# ---------------------------------------------------------------------------
# Main simulator
# ---------------------------------------------------------------------------

class MedDialogSimulator:
    """
    åŸºäºä¸­å›½åŒ»ç–—å¯¹è¯æ•°æ®é›†çš„æ‚£è€…-åŒ»ç”Ÿå¯¹è¯æ¨¡æ‹Ÿå™¨ã€‚

    æ ¸å¿ƒåŠŸèƒ½
    --------
    1. **è§£ææ•°æ®é›†** â€” ä» Medical-Dialogue-Dataset-Chinese ä¸­åŠ è½½çœŸå®è®°å½•ã€‚
    2. **æ¨¡æ‹Ÿå¯¹è¯** â€” ä½¿ç”¨ Gemini / OpenAI ç­‰ AI æ¨¡å‹ï¼ŒåŸºäºçœŸå®ç—…ä¾‹ç”Ÿæˆ
       å¤šè½®æ‚£è€…-åŒ»ç”Ÿå¯¹è¯ã€‚
    3. **å¤šç§æ¨¡å¼** â€” æ”¯æŒ AI åŒæ—¶æ‰®æ¼”åŒæ–¹ / AI æ‰®æ¼”åŒ»ç”Ÿï¼ˆç”¨æˆ·æ‰®æ¼”æ‚£è€…ï¼‰
       / AI æ‰®æ¼”æ‚£è€…ï¼ˆç”¨æˆ·æ‰®æ¼”åŒ»ç”Ÿï¼‰ç­‰æ¨¡å¼ã€‚

    Quick Start
    -----------
    >>> sim = MedDialogSimulator(
    ...     dataset_dir="Medical-Dialogue-Dataset-Chinese",
    ...     backend=GeminiBackend(api_key="YOUR_KEY"),
    ... )
    >>> records = sim.load_records("2020.txt", limit=10)
    >>> result = sim.simulate(records[3], max_turns=6)
    >>> print(result.formatted())
    """

    def __init__(
        self,
        dataset_dir: str | Path,
        backend: BaseModelBackend | None = None,
    ):
        """
        Parameters
        ----------
        dataset_dir : str | Path
            Medical-Dialogue-Dataset-Chinese æ•°æ®é›†ç›®å½•è·¯å¾„ã€‚
        backend : BaseModelBackend | None
            AI æ¨¡å‹åç«¯å®ä¾‹ã€‚ä¼  None æ—¶åªèƒ½ä½¿ç”¨è§£æåŠŸèƒ½ï¼Œä¸èƒ½æ¨¡æ‹Ÿå¯¹è¯ã€‚
        """
        self.parser = DatasetParser(dataset_dir)
        self.backend = backend
        self._records_cache: dict[str, list[MedicalRecord]] = {}

    # ------------------------------------------------------------------ #
    # æ•°æ®åŠ è½½
    # ------------------------------------------------------------------ #
    def list_files(self) -> list[str]:
        """åˆ—å‡ºæ•°æ®é›†ä¸­å¯ç”¨çš„æ–‡ä»¶åã€‚"""
        return [f.name for f in self.parser.available_files()]

    def load_records(
        self,
        filename: str,
        *,
        limit: int | None = None,
        cache: bool = True,
    ) -> list[MedicalRecord]:
        """
        åŠ è½½æŒ‡å®šæ–‡ä»¶çš„è®°å½•ã€‚

        Parameters
        ----------
        filename : str
            æ–‡ä»¶åï¼Œä¾‹å¦‚ '2020.txt'ã€‚
        limit : int | None
            æœ€å¤šåŠ è½½å¤šå°‘æ¡ã€‚
        cache : bool
            æ˜¯å¦ç¼“å­˜ç»“æœã€‚
        """
        key = f"{filename}:{limit}"
        if cache and key in self._records_cache:
            return self._records_cache[key]

        filepath = self.parser.dataset_dir / filename
        records = self.parser.parse_file(filepath, limit=limit)

        if cache:
            self._records_cache[key] = records
        return records

    def sample_records(
        self,
        filename: str,
        n: int = 5,
        *,
        with_dialogue: bool = True,
        seed: int | None = None,
    ) -> list[MedicalRecord]:
        """ä»æŒ‡å®šæ–‡ä»¶ä¸­éšæœºé‡‡æ · n æ¡è®°å½•ã€‚"""
        filepath = self.parser.dataset_dir / filename
        return self.parser.sample_records(
            filepath, n, with_dialogue=with_dialogue, seed=seed
        )

    def get_record(self, filename: str, record_id: int) -> MedicalRecord | None:
        """æŒ‰ record_id ä»æ–‡ä»¶ä¸­æŸ¥æ‰¾ç‰¹å®šè®°å½•ã€‚"""
        for rec in self.parser.iter_records(self.parser.dataset_dir / filename):
            if rec.record_id == record_id:
                return rec
        return None

    # ------------------------------------------------------------------ #
    # å¯¹è¯æ¨¡æ‹Ÿ
    # ------------------------------------------------------------------ #

    @dataclass
    class SimulationResult:
        """æ¨¡æ‹Ÿå¯¹è¯çš„ç»“æœã€‚"""
        record: MedicalRecord
        simulated_dialogue: list[DialogueTurn] = field(default_factory=list)
        mode: str = ""
        model_name: str = ""

        def formatted(self) -> str:
            """æ ¼å¼åŒ–è¾“å‡ºæ¨¡æ‹Ÿç»“æœã€‚"""
            sep = "=" * 60
            lines = [
                sep,
                f"ğŸ“‹ ç—…ä¾‹ ID: {self.record.record_id}",
                f"ğŸ¥ {self.record.hospital} - {self.record.department}",
                f"ğŸ¤– æ¨¡å‹: {self.model_name}  |  æ¨¡å¼: {self.mode}",
                sep,
                "",
                "ã€æ‚£è€…ä¿¡æ¯ã€‘",
                self.record.patient_profile_prompt(),
                "",
                "--- æ¨¡æ‹Ÿå¯¹è¯ ---",
            ]
            for turn in self.simulated_dialogue:
                icon = "ğŸ§‘â€âš•ï¸ åŒ»ç”Ÿ" if turn.role == "doctor" else "ğŸ¤’ ç—…äºº"
                lines.append(f"{icon}ï¼š{turn.text}")
            lines.append("")

            if self.record.dialogue:
                lines.append("--- çœŸå®å¯¹è¯ï¼ˆå‚è€ƒï¼‰ ---")
                lines.append(self.record.reference_dialogue_text())
                lines.append("")

            if self.record.diagnosis:
                lines.append(f"ğŸ“Œ å‚è€ƒè¯Šæ–­: {self.record.diagnosis}")
            if self.record.suggestion:
                lines.append(f"ğŸ’¡ å‚è€ƒå»ºè®®: {self.record.suggestion}")
            lines.append(sep)
            return "\n".join(lines)

        def to_dict(self) -> dict:
            return {
                "record": self.record.to_dict(),
                "simulated_dialogue": [
                    {"role": t.role, "text": t.text}
                    for t in self.simulated_dialogue
                ],
                "mode": self.mode,
                "model_name": self.model_name,
            }

    def simulate(
        self,
        record: MedicalRecord,
        *,
        max_turns: int = 8,
        temperature: float = 0.7,
        mode: Literal["auto", "doctor", "patient"] = "auto",
    ) -> SimulationResult:
        """
        åŸºäºçœŸå®ç—…ä¾‹è®°å½•æ¨¡æ‹Ÿå¤šè½®å¯¹è¯ã€‚

        Parameters
        ----------
        record : MedicalRecord
            çœŸå®åŒ»ç–—è®°å½•ã€‚
        max_turns : int
            æœ€å¤§å¯¹è¯è½®æ¬¡ï¼ˆä¸€é—®ä¸€ç­”ç®— 2 è½®ï¼‰ã€‚
        temperature : float
            ç”Ÿæˆæ¸©åº¦ã€‚
        mode : str
            - 'auto'   : AI åŒæ—¶æ‰®æ¼”åŒ»ç”Ÿå’Œæ‚£è€…ï¼Œè‡ªåŠ¨ç”Ÿæˆå®Œæ•´å¯¹è¯ã€‚
            - 'doctor' : AI æ‰®æ¼”åŒ»ç”Ÿï¼Œéœ€ç”¨æˆ·æ‰®æ¼”æ‚£è€…ï¼ˆäº¤äº’æ¨¡å¼ï¼Œ
                         æ­¤å¤„ç®€åŒ–ä¸º AI æ ¹æ®æ‚£è€…ä¿¡æ¯è‡ªåŠ¨æ¨¡æ‹Ÿé¦–è½®åç”Ÿæˆï¼‰ã€‚
            - 'patient': AI æ‰®æ¼”æ‚£è€…ã€‚
        """
        if self.backend is None:
            raise RuntimeError("æœªè®¾ç½® AI æ¨¡å‹åç«¯ï¼Œæ— æ³•è¿›è¡Œå¯¹è¯æ¨¡æ‹Ÿã€‚")

        if mode == "auto":
            return self._simulate_auto(record, max_turns, temperature)
        elif mode == "doctor":
            return self._simulate_as_doctor(record, max_turns, temperature)
        elif mode == "patient":
            return self._simulate_as_patient(record, max_turns, temperature)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å¼: {mode}")

    # ---- Auto æ¨¡å¼ï¼šAI ä¸€æ¬¡æ€§ç”Ÿæˆå®Œæ•´å¤šè½®å¯¹è¯ ----
    def _simulate_auto(
        self, record: MedicalRecord, max_turns: int, temperature: float
    ) -> SimulationResult:
        system_prompt = textwrap.dedent(f"""\
            ä½ æ˜¯ä¸€ä¸ªåŒ»ç–—å¯¹è¯æ¨¡æ‹Ÿå™¨ã€‚è¯·æ ¹æ®ä»¥ä¸‹çœŸå®ç—…ä¾‹ä¿¡æ¯ï¼Œæ¨¡æ‹Ÿä¸€æ®µæ‚£è€…ä¸åŒ»ç”Ÿä¹‹é—´çš„å¤šè½®ä¸­æ–‡å¯¹è¯ã€‚

            è¦æ±‚ï¼š
            1. å¯¹è¯è¦è‡ªç„¶ã€ä¸“ä¸šã€ç¬¦åˆçœŸå®åŒ»ç–—åœºæ™¯ã€‚
            2. åŒ»ç”Ÿåº”å½“è€å¿ƒè¯¢é—®ç—…æƒ…ã€ç»™å‡ºä¸“ä¸šå»ºè®®ã€‚
            3. æ‚£è€…åº”å½“æ ¹æ®ç—…æƒ…æè¿°è‡ªç„¶åœ°å›ç­”å’Œæé—®ã€‚
            4. å…±ç”Ÿæˆ {max_turns} è½®å¯¹è¯ï¼ˆä¸€è½® = ä¸€æ–¹è¯´ä¸€å¥è¯ï¼‰ã€‚
            5. ä¸¥æ ¼æŒ‰å¦‚ä¸‹æ ¼å¼è¾“å‡ºï¼Œæ¯è¡Œä¸€å¥ï¼Œä¸è¦åŠ é¢å¤–æ ‡è®°ï¼š
               ç—…äººï¼š...
               åŒ»ç”Ÿï¼š...
               ç—…äººï¼š...
               åŒ»ç”Ÿï¼š...

            ã€æ‚£è€…ä¿¡æ¯ã€‘
            {record.patient_profile_prompt()}

            ã€åŒ»ç”Ÿä¿¡æ¯ã€‘
            {record.doctor_profile_prompt()}
        """)

        ref_hint = ""
        if record.dialogue:
            ref_hint = (
                "\n\nä»¥ä¸‹æ˜¯çœŸå®å¯¹è¯ç‰‡æ®µä½œä¸ºå‚è€ƒé£æ ¼ï¼ˆè¯·ä¸è¦ç…§æŠ„ï¼Œè€Œæ˜¯æ¨¡æ‹Ÿç±»ä¼¼é£æ ¼ï¼‰ï¼š\n"
                + record.reference_dialogue_text()
            )

        messages = [
            {"role": "user", "text": system_prompt + ref_hint},
        ]

        raw = self.backend.generate(messages, temperature=temperature)
        turns = self._parse_generated_dialogue(raw)

        return self.SimulationResult(
            record=record,
            simulated_dialogue=turns,
            mode="auto",
            model_name=self.backend.name,
        )

    # ---- Doctor æ¨¡å¼ï¼šAI æ‰®æ¼”åŒ»ç”Ÿ ----
    def _simulate_as_doctor(
        self, record: MedicalRecord, max_turns: int, temperature: float
    ) -> SimulationResult:
        system_prompt = textwrap.dedent(f"""\
            ä½ ç°åœ¨æ‰®æ¼”ä¸€åä¸­å›½çš„ä¸“ç§‘åŒ»ç”Ÿï¼Œåœ¨çº¿ä¸Šé—®è¯Šå¹³å°å›ç­”æ‚£è€…çš„é—®é¢˜ã€‚

            ä½ çš„èƒŒæ™¯ä¿¡æ¯ï¼š
            {record.doctor_profile_prompt()}

            è¦æ±‚ï¼š
            1. ç”¨ä¸­æ–‡ã€ä¸“ä¸šä½†é€šä¿—æ˜“æ‡‚çš„è¯­è¨€ä¸æ‚£è€…äº¤æµã€‚
            2. ä¸»åŠ¨è¯¢é—®ç›¸å…³ç—…å²ã€ç—‡çŠ¶ç»†èŠ‚ã€‚
            3. ç»™å‡ºåˆç†çš„å»ºè®®å’Œåˆæ­¥åˆ¤æ–­ã€‚
            4. æ¯æ¬¡åªå›å¤åŒ»ç”Ÿçš„ä¸€å¥è¯ã€‚
        """)

        dialogue_turns: list[DialogueTurn] = []
        messages = [{"role": "user", "text": system_prompt}]

        # ç”¨çœŸå®ç—…æƒ…æè¿°ä½œä¸ºæ‚£è€…çš„ç¬¬ä¸€å¥è¯
        first_patient_msg = f"åŒ»ç”Ÿä½ å¥½ï¼Œ{record.description}"
        if record.hope:
            first_patient_msg += f" {record.hope}"

        for turn_idx in range(max_turns):
            if turn_idx % 2 == 0:
                # æ‚£è€…å›åˆ
                if turn_idx == 0:
                    patient_text = first_patient_msg
                else:
                    # ä½¿ç”¨å¦ä¸€æ¬¡ LLM è°ƒç”¨ç”Ÿæˆæ‚£è€…å›å¤
                    patient_text = self._generate_patient_reply(
                        record, dialogue_turns, temperature
                    )
                dialogue_turns.append(DialogueTurn(role="patient", text=patient_text))
                messages.append({"role": "user", "text": patient_text})
            else:
                # åŒ»ç”Ÿå›åˆï¼ˆAI ç”Ÿæˆï¼‰
                doctor_reply = self.backend.generate(messages, temperature=temperature)
                doctor_reply = self._clean_role_prefix(doctor_reply, "åŒ»ç”Ÿ")
                dialogue_turns.append(DialogueTurn(role="doctor", text=doctor_reply))
                messages.append({"role": "model", "text": doctor_reply})

        return self.SimulationResult(
            record=record,
            simulated_dialogue=dialogue_turns,
            mode="doctor",
            model_name=self.backend.name,
        )

    # ---- Patient æ¨¡å¼ï¼šAI æ‰®æ¼”æ‚£è€… ----
    def _simulate_as_patient(
        self, record: MedicalRecord, max_turns: int, temperature: float
    ) -> SimulationResult:
        system_prompt = textwrap.dedent(f"""\
            ä½ ç°åœ¨æ‰®æ¼”ä¸€åæ‚£è€…ï¼Œåœ¨çº¿ä¸Šé—®è¯Šå¹³å°å‘åŒ»ç”Ÿå’¨è¯¢ã€‚

            ä½ çš„ç—…æƒ…ä¿¡æ¯å¦‚ä¸‹ï¼ˆè¯·ä¸¥æ ¼åŸºäºè¿™äº›ä¿¡æ¯å›ç­”ï¼Œä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„ç—‡çŠ¶ï¼‰ï¼š
            {record.patient_profile_prompt()}

            è¦æ±‚ï¼š
            1. ç”¨ä¸­æ–‡è‡ªç„¶å£è¯­ä¸åŒ»ç”Ÿäº¤æµã€‚
            2. å¦‚å®æè¿°è‡ªå·±çš„ç—‡çŠ¶å’Œæ‹…å¿§ã€‚
            3. æ¯æ¬¡åªå›å¤æ‚£è€…çš„ä¸€å¥è¯ã€‚
        """)

        dialogue_turns: list[DialogueTurn] = []
        messages = [{"role": "user", "text": system_prompt}]

        for turn_idx in range(max_turns):
            if turn_idx % 2 == 0:
                # æ‚£è€…å›åˆï¼ˆAI ç”Ÿæˆï¼‰
                if turn_idx == 0:
                    patient_prompt = "è¯·ä»¥æ‚£è€…èº«ä»½æè¿°ä½ çš„ç—‡çŠ¶ï¼Œå‘åŒ»ç”Ÿé—®å¥½å¹¶è¯´æ˜æ¥æ„ã€‚"
                    messages.append({"role": "user", "text": patient_prompt})

                patient_reply = self.backend.generate(messages, temperature=temperature)
                patient_reply = self._clean_role_prefix(patient_reply, "ç—…äºº")
                dialogue_turns.append(DialogueTurn(role="patient", text=patient_reply))
                messages.append({"role": "model", "text": patient_reply})
            else:
                # åŒ»ç”Ÿå›åˆ â€” æ¨¡æ‹ŸåŒ»ç”Ÿå›å¤
                doctor_text = self._generate_doctor_reply(
                    record, dialogue_turns, temperature
                )
                dialogue_turns.append(DialogueTurn(role="doctor", text=doctor_text))
                messages.append({"role": "user", "text": f"ï¼ˆåŒ»ç”Ÿå›å¤ï¼‰{doctor_text}"})

        return self.SimulationResult(
            record=record,
            simulated_dialogue=dialogue_turns,
            mode="patient",
            model_name=self.backend.name,
        )

    # ------------------------------------------------------------------ #
    # äº¤äº’æ¨¡å¼
    # ------------------------------------------------------------------ #
    def interactive_chat(
        self,
        record: MedicalRecord,
        *,
        user_role: Literal["patient", "doctor"] = "patient",
        temperature: float = 0.7,
    ) -> SimulationResult:
        """
        äº¤äº’å¼å¯¹è¯ â€” ç”¨æˆ·åœ¨ç»ˆç«¯ä¸­å®æ—¶è¾“å…¥ï¼ŒAI æ‰®æ¼”å¦ä¸€æ–¹ã€‚

        Parameters
        ----------
        record : MedicalRecord
            ç—…ä¾‹è®°å½•ã€‚
        user_role : str
            ç”¨æˆ·æ‰®æ¼”çš„è§’è‰²ï¼š'patient'(ç—…äºº) æˆ– 'doctor'(åŒ»ç”Ÿ)ã€‚
        """
        if self.backend is None:
            raise RuntimeError("æœªè®¾ç½® AI æ¨¡å‹åç«¯ã€‚")

        ai_role = "doctor" if user_role == "patient" else "patient"
        ai_label = "ğŸ§‘â€âš•ï¸ åŒ»ç”Ÿ" if ai_role == "doctor" else "ğŸ¤’ ç—…äºº"
        user_label = "ğŸ¤’ ç—…äºº(ä½ )" if user_role == "patient" else "ğŸ§‘â€âš•ï¸ åŒ»ç”Ÿ(ä½ )"

        if ai_role == "doctor":
            system_prompt = textwrap.dedent(f"""\
                ä½ ç°åœ¨æ‰®æ¼”ä¸€åä¸­å›½çš„ä¸“ç§‘åŒ»ç”Ÿï¼Œåœ¨çº¿é—®è¯Šã€‚
                {record.doctor_profile_prompt()}
                è¯·ç”¨ä¸­æ–‡ä¸“ä¸šä½†é€šä¿—çš„è¯­è¨€å›å¤ã€‚æ¯æ¬¡åªå›å¤ä¸€å¥è¯ã€‚
            """)
        else:
            system_prompt = textwrap.dedent(f"""\
                ä½ ç°åœ¨æ‰®æ¼”ä¸€åæ‚£è€…ï¼Œåœ¨çº¿é—®è¯Šã€‚
                {record.patient_profile_prompt()}
                è¯·åŸºäºä»¥ä¸Šç—…æƒ…ä¿¡æ¯ç”¨ä¸­æ–‡è‡ªç„¶å£è¯­å›å¤ã€‚æ¯æ¬¡åªå›å¤ä¸€å¥è¯ã€‚
            """)

        print("=" * 60)
        print(f"ğŸ“‹ ç—…ä¾‹: {record.disease}")
        print(f"ğŸ¥ {record.hospital} - {record.department}")
        print(f"ä½ çš„è§’è‰²: {user_label}  |  AI è§’è‰²: {ai_label}")
        print("è¾“å…¥ 'quit' æˆ– 'exit' ç»“æŸå¯¹è¯")
        print("=" * 60)

        messages = [{"role": "user", "text": system_prompt}]
        dialogue_turns: list[DialogueTurn] = []

        while True:
            user_input = input(f"\n{user_label}ï¼š").strip()
            if user_input.lower() in ("quit", "exit", "q"):
                break
            if not user_input:
                continue

            dialogue_turns.append(DialogueTurn(role=user_role, text=user_input))
            messages.append({"role": "user", "text": user_input})

            ai_reply = self.backend.generate(messages, temperature=temperature)
            ai_reply = self._clean_role_prefix(
                ai_reply, "åŒ»ç”Ÿ" if ai_role == "doctor" else "ç—…äºº"
            )
            print(f"{ai_label}ï¼š{ai_reply}")

            dialogue_turns.append(DialogueTurn(role=ai_role, text=ai_reply))
            messages.append({"role": "model", "text": ai_reply})

        return self.SimulationResult(
            record=record,
            simulated_dialogue=dialogue_turns,
            mode=f"interactive-{user_role}",
            model_name=self.backend.name,
        )

    # ------------------------------------------------------------------ #
    # æ‰¹é‡æ¨¡æ‹Ÿ & å¯¼å‡º
    # ------------------------------------------------------------------ #
    def batch_simulate(
        self,
        records: list[MedicalRecord],
        *,
        max_turns: int = 8,
        temperature: float = 0.7,
        mode: Literal["auto", "doctor", "patient"] = "auto",
        verbose: bool = True,
    ) -> list[SimulationResult]:
        """å¯¹å¤šæ¡è®°å½•æ‰¹é‡æ¨¡æ‹Ÿå¯¹è¯ã€‚"""
        results: list[MedDialogSimulator.SimulationResult] = []
        for i, rec in enumerate(records):
            if verbose:
                print(f"[{i + 1}/{len(records)}] æ¨¡æ‹Ÿ id={rec.record_id} ...")
            result = self.simulate(
                rec, max_turns=max_turns, temperature=temperature, mode=mode
            )
            results.append(result)
        return results

    @staticmethod
    def export_results(
        results: list[SimulationResult],
        output_path: str | Path,
        *,
        format: Literal["json", "txt"] = "json",
    ) -> None:
        """
        å°†æ¨¡æ‹Ÿç»“æœå¯¼å‡ºåˆ°æ–‡ä»¶ã€‚

        Parameters
        ----------
        format : str
            'json' â€” ç»“æ„åŒ– JSONï¼›'txt' â€” äººç±»å¯è¯»æ–‡æœ¬ã€‚
        """
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        if format == "json":
            data = [r.to_dict() for r in results]
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        elif format == "txt":
            with open(output_path, "w", encoding="utf-8") as f:
                for r in results:
                    f.write(r.formatted())
                    f.write("\n\n")
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format}")

        print(f"âœ… å·²å¯¼å‡º {len(results)} æ¡ç»“æœåˆ° {output_path}")

    # ------------------------------------------------------------------ #
    # è¾…åŠ©æ–¹æ³•
    # ------------------------------------------------------------------ #
    def _generate_patient_reply(
        self,
        record: MedicalRecord,
        history: list[DialogueTurn],
        temperature: float,
    ) -> str:
        """åŸºäºç—…ä¾‹ä¿¡æ¯å’Œå·²æœ‰å¯¹è¯å†å²ï¼Œç”Ÿæˆæ‚£è€…å›å¤ã€‚"""
        history_text = "\n".join(
            f"{'ç—…äºº' if t.role == 'patient' else 'åŒ»ç”Ÿ'}ï¼š{t.text}" for t in history
        )
        prompt = textwrap.dedent(f"""\
            ä½ æ‰®æ¼”ä¸€åæ‚£è€…ï¼Œæ­£åœ¨å’ŒåŒ»ç”Ÿåœ¨çº¿é—®è¯Šã€‚

            ä½ çš„ç—…æƒ…ä¿¡æ¯ï¼š
            {record.patient_profile_prompt()}

            ç›®å‰çš„å¯¹è¯å†å²ï¼š
            {history_text}

            è¯·ä»¥æ‚£è€…èº«ä»½è‡ªç„¶åœ°å›å¤åŒ»ç”Ÿçš„ä¸Šä¸€å¥è¯ã€‚åªè¾“å‡ºæ‚£è€…çš„ä¸€å¥è¯ï¼Œä¸è¦åŠ è§’è‰²æ ‡ç­¾ã€‚
        """)
        messages = [{"role": "user", "text": prompt}]
        reply = self.backend.generate(messages, temperature=temperature)
        return self._clean_role_prefix(reply, "ç—…äºº")

    def _generate_doctor_reply(
        self,
        record: MedicalRecord,
        history: list[DialogueTurn],
        temperature: float,
    ) -> str:
        """åŸºäºç—…ä¾‹ä¿¡æ¯å’Œå·²æœ‰å¯¹è¯å†å²ï¼Œç”ŸæˆåŒ»ç”Ÿå›å¤ã€‚"""
        history_text = "\n".join(
            f"{'ç—…äºº' if t.role == 'patient' else 'åŒ»ç”Ÿ'}ï¼š{t.text}" for t in history
        )
        prompt = textwrap.dedent(f"""\
            ä½ æ‰®æ¼”ä¸€åä¸“ç§‘åŒ»ç”Ÿï¼Œæ­£åœ¨çº¿ä¸Šé—®è¯Šã€‚

            åŒ»ç”Ÿä¿¡æ¯ï¼š
            {record.doctor_profile_prompt()}

            ç›®å‰çš„å¯¹è¯å†å²ï¼š
            {history_text}

            è¯·ä»¥åŒ»ç”Ÿèº«ä»½ä¸“ä¸šåœ°å›å¤æ‚£è€…ã€‚åªè¾“å‡ºåŒ»ç”Ÿçš„ä¸€å¥è¯ï¼Œä¸è¦åŠ è§’è‰²æ ‡ç­¾ã€‚
        """)
        messages = [{"role": "user", "text": prompt}]
        reply = self.backend.generate(messages, temperature=temperature)
        return self._clean_role_prefix(reply, "åŒ»ç”Ÿ")

    @staticmethod
    def _parse_generated_dialogue(text: str) -> list[DialogueTurn]:
        """è§£æ AI ç”Ÿæˆçš„å¯¹è¯æ–‡æœ¬ã€‚"""
        turns: list[DialogueTurn] = []
        for line in text.strip().splitlines():
            line = line.strip()
            if not line:
                continue
            if line.startswith("ç—…äºº") or line.startswith("æ‚£è€…"):
                content = re.sub(r"^(ç—…äºº|æ‚£è€…)[ï¼š:]\s*", "", line)
                if content:
                    turns.append(DialogueTurn(role="patient", text=content))
            elif line.startswith("åŒ»ç”Ÿ"):
                content = re.sub(r"^åŒ»ç”Ÿ[ï¼š:]\s*", "", line)
                if content:
                    turns.append(DialogueTurn(role="doctor", text=content))
        return turns

    @staticmethod
    def _clean_role_prefix(text: str, role_label: str) -> str:
        """å»é™¤å›å¤æ–‡æœ¬å¼€å¤´å¯èƒ½å‡ºç°çš„è§’è‰²æ ‡ç­¾ã€‚"""
        text = text.strip()
        text = re.sub(rf"^{role_label}[ï¼š:]\s*", "", text)
        text = re.sub(r"^(ç—…äºº|æ‚£è€…|åŒ»ç”Ÿ)[ï¼š:]\s*", "", text)
        return text.strip()


# ---------------------------------------------------------------------------
# ä¾¿æ·å…¥å£ & CLI
# ---------------------------------------------------------------------------

def quick_demo(
    dataset_dir: str = "Medical-Dialogue-Dataset-Chinese",
    api_key: str | None = None,
    filename: str = "2020.txt",
    record_id: int | None = None,
    max_turns: int = 8,
    backend_type: str = "gemini",
    model: str | None = None,
):
    """
    å¿«é€Ÿæ¼”ç¤ºå‡½æ•°ã€‚

    Parameters
    ----------
    dataset_dir : str
        æ•°æ®é›†ç›®å½•ã€‚
    api_key : str | None
        API å¯†é’¥ï¼ˆä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®ï¼‰ã€‚
    filename : str
        è¦ä½¿ç”¨çš„æ•°æ®æ–‡ä»¶ã€‚
    record_id : int | None
        æŒ‡å®šè®°å½• IDï¼ŒNone åˆ™éšæœºé€‰æ‹©ã€‚
    max_turns : int
        å¯¹è¯è½®æ¬¡ã€‚
    backend_type : str
        'gemini' / 'chatgpt' / 'claude'ï¼ˆä»¥åŠå®ƒä»¬çš„åˆ«åï¼‰ã€‚
    model : str | None
        æ¨¡å‹åç§°ï¼ŒNone åˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹ã€‚
    """
    backend = create_backend(backend_type, api_key=api_key, model=model)

    sim = MedDialogSimulator(dataset_dir=dataset_dir, backend=backend)

    # åŠ è½½ / é€‰å–è®°å½•
    if record_id is not None:
        print(f"æ­£åœ¨æŸ¥æ‰¾ id={record_id} ...")
        record = sim.get_record(filename, record_id)
        if record is None:
            print(f"âŒ æœªæ‰¾åˆ° id={record_id}")
            return
    else:
        print(f"ä» {filename} éšæœºé‡‡æ · 1 æ¡å«å¯¹è¯çš„è®°å½• ...")
        records = sim.sample_records(filename, n=1, seed=42)
        if not records:
            print("âŒ æœªæ‰¾åˆ°åˆé€‚çš„è®°å½•")
            return
        record = records[0]

    print(f"âœ… é€‰ä¸­è®°å½• id={record.record_id}: {record.disease}\n")

    # æ¨¡æ‹Ÿå¯¹è¯
    result = sim.simulate(record, max_turns=max_turns, mode="auto")
    print(result.formatted())

    return result


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="MedDialogSimulator - åŒ»ç–—å¯¹è¯æ¨¡æ‹Ÿå™¨")
    parser.add_argument("--dataset-dir", default="Medical-Dialogue-Dataset-Chinese",
                        help="æ•°æ®é›†ç›®å½•è·¯å¾„")
    parser.add_argument("--file", default="2020.txt", help="æ•°æ®æ–‡ä»¶å")
    parser.add_argument("--record-id", type=int, default=None, help="æŒ‡å®šè®°å½• ID")
    parser.add_argument("--max-turns", type=int, default=8, help="æœ€å¤§å¯¹è¯è½®æ¬¡")
    parser.add_argument("--api-key", default=None, help="API å¯†é’¥")
    parser.add_argument("--backend", default="gemini",
                        choices=["gemini", "chatgpt", "openai", "claude"],
                        help="AI æ¨¡å‹åç«¯: gemini / chatgpt / claude")
    parser.add_argument("--model", default=None,
                        help="æ¨¡å‹åç§° (å¦‚ gemini-2.0-flash, gpt-4o, claude-sonnet-4-20250514)")
    parser.add_argument("--interactive", action="store_true",
                        help="å¯ç”¨äº¤äº’æ¨¡å¼")
    parser.add_argument("--user-role", default="patient", choices=["patient", "doctor"],
                        help="äº¤äº’æ¨¡å¼ä¸­ç”¨æˆ·æ‰®æ¼”çš„è§’è‰²")
    parser.add_argument("--parse-only", action="store_true",
                        help="ä»…è§£ææ•°æ®é›†ï¼Œä¸è¿›è¡Œæ¨¡æ‹Ÿ")

    args = parser.parse_args()

    if args.parse_only:
        # ä»…è§£æå¹¶å±•ç¤ºè®°å½•
        sim = MedDialogSimulator(dataset_dir=args.dataset_dir, backend=None)
        records = sim.load_records(args.file, limit=5)
        for rec in records:
            print(f"\n{'='*50}")
            print(f"ID: {rec.record_id}")
            print(f"åŒ»é™¢: {rec.hospital} | ç§‘å®¤: {rec.department}")
            print(f"ç–¾ç—…: {rec.disease}")
            print(f"æè¿°: {rec.description[:100]}...")
            if rec.dialogue:
                print(f"å¯¹è¯è½®æ•°: {len(rec.dialogue)}")
                print("--- å¯¹è¯æ‘˜å½• ---")
                for turn in rec.dialogue[:4]:
                    label = "ç—…äºº" if turn.role == "patient" else "åŒ»ç”Ÿ"
                    print(f"  {label}ï¼š{turn.text[:80]}")
    elif args.interactive:
        # äº¤äº’æ¨¡å¼
        backend = create_backend(args.backend, api_key=args.api_key, model=args.model)

        sim = MedDialogSimulator(dataset_dir=args.dataset_dir, backend=backend)

        if args.record_id is not None:
            record = sim.get_record(args.file, args.record_id)
        else:
            records = sim.sample_records(args.file, n=1, seed=42)
            record = records[0] if records else None

        if record:
            sim.interactive_chat(record, user_role=args.user_role)
        else:
            print("âŒ æœªæ‰¾åˆ°åˆé€‚çš„è®°å½•")
    else:
        quick_demo(
            dataset_dir=args.dataset_dir,
            api_key=args.api_key,
            filename=args.file,
            record_id=args.record_id,
            max_turns=args.max_turns,
            backend_type=args.backend,
            model=args.model,
        )
